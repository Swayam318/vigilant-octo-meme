{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6c9f0-9220-4565-97bf-901897dd396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Configuration\n",
    "IMAGE_DIR = '/kaggle/input/new-dataset/images'\n",
    "TRAIN_PATH = '/kaggle/input/new-dataset/train.csv'\n",
    "TEST_PATH = '/kaggle/input/new-dataset/test.csv'\n",
    "\n",
    "def preprocess_data():\n",
    "    print(\"Loading data...\")\n",
    "    train_df = pd.read_csv(TRAIN_PATH)\n",
    "    test_df = pd.read_csv(TEST_PATH)\n",
    "    \n",
    "    # 1. Handle Date\n",
    "    train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "    test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "    \n",
    "    train_df['date_int'] = train_df['date'].astype(np.int64) // 10**9\n",
    "    test_df['date_int'] = test_df['date'].astype(np.int64) // 10**9\n",
    "    \n",
    "    # 2. Log Transform Target (Price)\n",
    "    train_df['log_price'] = np.log1p(train_df['price'])\n",
    "    \n",
    "    # 3. Log Transform Skewed Input Features (Crucial for NN performance)\n",
    "    skewed_cols = ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', \n",
    "                   'sqft_living15', 'sqft_lot15']\n",
    "    \n",
    "    for col in skewed_cols:\n",
    "        # Fill NA with 0 just in case, though dataset is clean\n",
    "        train_df[col] = np.log1p(train_df[col].fillna(0))\n",
    "        test_df[col] = np.log1p(test_df[col].fillna(0))\n",
    "        print(f\"Log-transformed {col}\")\n",
    "\n",
    "    # 4. Feature Selection\n",
    "    drop_cols = ['id', 'date', 'price', 'log_price']\n",
    "    feature_cols = [c for c in train_df.columns if c not in drop_cols]\n",
    "    \n",
    "    print(f\"Selected {len(feature_cols)} tabular features.\")\n",
    "    \n",
    "    # 5. Scaling\n",
    "    scaler = StandardScaler()\n",
    "    train_df[feature_cols] = scaler.fit_transform(train_df[feature_cols])\n",
    "    test_df[feature_cols] = scaler.transform(test_df[feature_cols])\n",
    "    \n",
    "    joblib.dump(scaler, 'tabular_scaler.pkl')\n",
    "    \n",
    "    # 6. Image Path Mapping\n",
    "    def get_image_path(house_id):\n",
    "        path_jpg = os.path.join(IMAGE_DIR, f\"{house_id}.jpg\")\n",
    "        if os.path.exists(path_jpg): return path_jpg\n",
    "        path_png = os.path.join(IMAGE_DIR, f\"{house_id}.png\")\n",
    "        if os.path.exists(path_png): return path_png\n",
    "        return None \n",
    "\n",
    "    train_df['image_path'] = train_df['id'].apply(get_image_path)\n",
    "    test_df['image_path'] = test_df['id'].apply(get_image_path)\n",
    "    \n",
    "    print(\"Saving processed data...\")\n",
    "    train_df.to_csv('processed_train.csv', index=False)\n",
    "    test_df.to_csv('processed_test.csv', index=False)\n",
    "    print(\"Done. Files saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
